---
title: Regularized Multivariate Two-way Functional Principal Component Analysis
format:
  poster-typst: 
    size: "36x24"
    poster-authors: "Mobina Pourmoshir, Dr. Mehdi Maadooliat"
    departments: "Department of Mathematical and Statistical Sciences"
    institution-logo: "./images/MU.jpg"
    footer-text: "Marquette University"
    footer-url: "https://github.com/mobinapourmoshir/ReMPCA"
    footer-emails: "mobina.pourmoshir@marquette.edu"
    footer-color: "ebcfb2"
bibliography: ref.bib
csl: apa.csl
citeproc: true
---

# Background

- **Functional data are ubiquitous.**  
  Modern sensors yield curves, images, and surfaces observed over time/space.  
  Functional PCA (FPCA) summarizes such data with a few principal functions for interpretation and modeling [@ramsay2005functional].

- **Extensions exist but are isolated.**
  - *<span style="color:#b30000;">Smoothed</span> FPCA*: roughness penalties produce smoother, less noisy components [@silverman1996smoothed; @huang2008functional].
  - *<span style="color:#0033cc;">Sparse</span> FPCA*: sparsity zeros out unimportant regions, improving interpretability [@huang2008sparse; @SparsePCA2020].
  - *Multivariate FPCA (MFPCA)*: captures shared variation across multiple functional variables [@Happ_2018].
  - *Two-way functional data* (e.g., time × space): require structure in both domains.

- **Limitations.**  
  Classical FPCA is noise-sensitive and can yield rough, dense patterns; many methods address either <span style="color:#b30000;">smoothness</span> or <span style="color:#0033cc;">sparsity</span> , or are limited to univariate data.

- **Motivation.**  
  Develop a regularized FPCA framework that (i) handles **multivariate** and **two-way** functional structures,  (ii) imposes **<span style="color:#b30000;">smoothness</span>** (noise reduction) and **<span style="color:#0033cc;">sparsity</span>** (feature selection) *simultaneously* on scores and loadings,  and (iii) yields low-rank, interpretable, and stable components.  Recent work points in this direction but leaves room for a unified treatment and broader applicability [@haghbin2023regMFPCA].



# Methodology
### **Multivariate FPCA**

Concatenate $p$ functional variables, where the $i$-th variable is observed on $m_i$ grid points, into $\mathbf{X} = \big[\,{X_1}\quad X_2 \; \cdots \; {X_p}\,\big] \in\mathbb{R}^{n\times M}$, where $M = \sum_{i=1}^p m_i$:

$$
\mathbf{X} =
\begin{bmatrix}
{x_{11}(t_{11})} & {\cdots} & {x_{11}(t_{1m_1})} & \cdots & {x_{1p}(t_{p1})} & {\cdots} & {x_{1p}(t_{p m_p})} \\
{\vdots} & {\ddots} & {\vdots} & \ddots & {\vdots} & {\ddots} & {\vdots} \\
{x_{n1}(t_{11})} & {\cdots} & {x_{n1}(t_{1m_1})} & \cdots & {x_{np}(t_{p1})} & {\cdots} & {x_{np}(t_{p m_p})}
\end{bmatrix}
$$


We estimate a rank-one structure with penalties:

$$
\min_{u,v}\;\|\mathbf{X}-uv^\top\|_F^2
+ \alpha\, u^\top u v^\top \boldsymbol{\Omega} v
+ p_\gamma(v),
$$

where $\boldsymbol{\Omega} = \mathrm{diag}(\Omega_1,\ldots,\Omega_p)$ encodes **<span style="color:#b30000;">roughness</span>** and $p_\gamma(\cdot)$ induces **<span style="color:#0033cc;">sparsity</span>** (soft, hard, or SCAD) [@huang2008functional; @huang2008sparse; @SparsePCA2020].


### **Sequential Power Algorithm**

Let $S(\alpha) = (I + \alpha \boldsymbol{\Omega})^{-1}$. Iterate:

1. **Initialize:** $v$ via rank-one SVD of $\mathbf{X}$.
2. **Repeat:**  
   - $u \leftarrow \mathbf{X}v$  
   - $v \leftarrow S(\alpha)\,h_\gamma(\mathbf{X}^\top u)$  
   - $v \leftarrow v / \|v\|$

**Tuning:**  
Choose $\gamma$ by $K$-fold cross-validation.  
Choose $\alpha$ by generalized cross-validation: $\mathrm{GCV}(\alpha) = \frac{\| (I - S(\alpha))(\mathbf{X}^\top u)\|^2 / M}{ \left( 1 - \tfrac{1}{M} \operatorname{tr} S(\alpha) \right)^2}.$



# Two-way Regularized MFPCA

- **Two-way functional data:**  
  Two-way functional data consist of a data matrix whose row and column domains are both structured. Classical FPCA focuses on one domain and penalizes only one set of components, often ignoring structure in the second direction.


- **Framework & Penalty:**  
  $$
  \min_{u,v} \|\pmb X - uv^\top\|_F^2 + 
    \sum_j^J \mathcal P_j^{[\theta]}(u,v)
  $$
- where $J$ is the number of penalty components, and $\theta$ is the vector of all tuning parameters. The composite penalty $\sum_{j=1}^J \mathcal{P}_j^{(\theta)}(u,v)$ lets us mix regularizers, e.g., <span style="color:#b30000;">smoothness</span> with $\theta=(\alpha_u,\boldsymbol{\alpha}_v)$ and <span style="color:#0033cc;">sparsity</span> with $\theta=(\gamma_u,\boldsymbol{\gamma}_v)$ (controlling sparsity), and can include other structures as needed.


- **Sequential Power Algorithm:**  
  1. Initialize $u, v$ using rank-one SVD of $\mathbf{X}$.  
  2. Update $u$ with smoothing and sparsity transformations:  
     $u \leftarrow S_u^{[\alpha_u]} h_u^{[\gamma_u]}(\mathbf{X}v)$  
  3. Update $v$ similarly:  
     $v \leftarrow S_v^{[\boldsymbol{\alpha}_v]} h_v^{[\boldsymbol{\gamma}_v]}(\mathbf{X}^\top u)$  
  4. Normalize $v$ and deflate $\mathbf{X}$ to extract further components.
  
- **Tuning parameters:**  
  - $\alpha_u$, $\boldsymbol{\alpha}_v$ → **<span style="color:#b30000;">smoothness</span>** of $u$ and $v$.  
  - $\gamma_u$, $\boldsymbol{\gamma}_v$ → **<span style="color:#0033cc;">sparsity</span>** of $u$ and $v$.
  - **Conditional tuning strategy:**  
    1. Start with no penalties.  
    2. Tune sparsity parameters via CV.  
    3. Tune smoothness parameters via GCV.  
    4. Alternate until convergence.

<div style="height: 30px;"></div>

```{=typst}
#grid(
  columns: 4,
  gutter: 2pt,  // reduce spacing between images

  // Row 1
  image("images/True.svg", width: 2.5in),
  image("images/svd_Reconstructed.svg", width: 2.5in),
  image("images/Lasso_reconstructed.svg", width: 2.5in),
  image("images/u1plots.svg", width: 2.5in),

  // Row 2
  image("images/NoisyChessboard.svg", width: 2.5in),
  image("images/smooth_reconstructed.svg", width: 2.5in),
  image("images/pic.compress.svg", width: 2.5in),
  image("images/v1plots.svg", width: 2.5in),
)
```





# Conclusion 
- **Comprehensive Framework:** ReMPCA extends PCA to functional data, combining smoothness (denoising) and sparsity (feature selection) for structured, low-rank PCs.
- **Methodology:** Penalized SVD with <span style="color:#b30000;">roughness</span> and <span style="color:#0033cc;">sparsity</span> penalties applies regularization to both scores ($u$) and loadings ($v$), tuned via GCV and CV.
- **Results:** Two-way regularization improves reconstruction and interpretability, outperforming one-way methods across simulated and real datasets.
- **Software:** Implemented in the ReMPCA R package with tuning, and visualization tools.
- **Future Work:** Extend to hybrid scalar–functional–image data, nonlinear kernels, and applications in neuroimaging, medicine, and environmental science.
  

```{=typst}
#align(center,
  grid(
    columns: 1,
    row-gutter: 0pt,
    image("images/plot1.svg", width: 9in),
    image("images/plot2.svg", width: 9in),
    image("images/plot3.svg", width: 9in),
  )
)
```


# References
```{=typst}
#set text(size: 9pt)
```

